# 统计学习方法概论

## 1.3 统计学习三要素
### 1.3.1 模型
假设空间用F表示。假设空间可以定义为决策函数的集合
$$
F = {f|Y=f(X)}
$$
其中，X和Y是定义在输入空间X和输出空间Y上的变量。这时F通常是一个参数向量决定的函数族：
$$
F = \{f|Y=f_{\theta}(X),\theta \in R^n\}
$$
$\theta$ 属于参数空间。
假设空间也可以定义为条件概率的集合
$$
F = \{P(Y|x)\}
$$
其中，X和Y是定义在输入空间X和输出空间Y上的随机变量。这时F通常是一个参数向量决定的条件概率分布族：
$$ 
F = \{P|P_{\theta}(Y|X),\theta \in R^n\}
$$
### 1.3.2 策略
损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型的好坏。将损失函数记作$L(Y,f(X))$
1. 损失函数和风险函数
损失函数的期望为：$$R_{exp}(f) = E_p[L(Y, f(X))] = \int_{X×y}L(y,f(x))P(x,y)dxdy$$
这是理论上模型 $f(X)$关于联合分布$P(X,Y)$的平均意义下的损失，称为风险函数（risk function）或期望损失（expected loss）。
$f(x)$ 关于训练数据集的平均损失称为经验风险或经验损失。
2. 经验风险最小化与结构风险最小化
经验风险最小化（ERM）的策略认为，经验风险最小化的模型就是最优的模型。根据这一策略，按照经验最小化求最优模型就是求解最优化问题。$$min_{f \in F} \frac{1}{N} \sum_{i=1}^{N}L(y_i,f(x_i))$$
**当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计。**  
**SRM**是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化。其定义为
$$R_{srm}(f) = \frac{1}{N} \sum_{i=1}^{N}L(y_i, f(x_i)) + \lambda J(f)$$

## 1.4 模型评估与模型选择
### 1.4.1 训练误差与测试误差
假设学习到的模型是$Y=\hat{f}(X)$，训练误差是模型$Y=\hat(f)(X)$关于训练数据集的平均损失。测试误差同理。定义误差率（error rate）准确率（accuracy）。显然：
$$r_{test} + e_{test} = 1$$




## 1.5 正则化与交叉验证
### 1.5.1 正则化
正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项（regularizer）或罚项(penalty term)．正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大．比如，正则化项可以是模型参数向量的范数。

正则化一般具有如下形式:
$$
min \frac{1}{N}\sum_{i=1}^{N}(L(y_i,f(x_i)))+\lambda J(f)
$$
正则化可以取不同形式，例如$J(f)= \frac{\lambda}{2}||w^2||$，取$L_{2}$作为惩罚项（岭回归）。  
$J(f)=\lambda||w||$，取$L_{1}$作为惩罚项（Lasso），将$L_{1}$作为0范数的近似，从而得到一个相对稀疏的解。  
正则化可以控制模型复杂度和经验风险。
### 1.5.2 交叉验证
1. 简单交叉验证，划分训练集和测试集
2. K折交叉验证
3. 留一法

## 1.6 泛化能力
### 1.6.1 泛化误差
泛化误差的定义。如果学到的模型是$\hat(f)$，那么用这个模型对未知数据预测的误差即为泛化误差(generalization error)
$$ R_{exp}(\hat{f}) = E_p[L(Y,\hat{f}(X))] = \int _{X×y}L(y, \hat{f}(x))P(x,y)dxdy$$

